{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports.\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# TensorFlow imports.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "from datasets.loading import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert#loading_models_from_tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading & merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>95333_912</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>912</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Family-history-of-migraines</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>95333_913</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>913</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Female</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>95333_914</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>914</td>\n",
       "      <td>[photobia]</td>\n",
       "      <td>[274 282]</td>\n",
       "      <td>Photophobia</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>95333_915</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>915</td>\n",
       "      <td>[no sick contacts]</td>\n",
       "      <td>[421 437]</td>\n",
       "      <td>No-known-illness-contacts</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>95333_916</td>\n",
       "      <td>9</td>\n",
       "      <td>95333</td>\n",
       "      <td>916</td>\n",
       "      <td>[Subjective fever]</td>\n",
       "      <td>[314 330]</td>\n",
       "      <td>Subjective-fever</td>\n",
       "      <td>Stephanie madden is a 20 year old woman compla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14300 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  case_num  pn_num  feature_num  \\\n",
       "0      00016_000         0      16            0   \n",
       "1      00016_001         0      16            1   \n",
       "2      00016_002         0      16            2   \n",
       "3      00016_003         0      16            3   \n",
       "4      00016_004         0      16            4   \n",
       "...          ...       ...     ...          ...   \n",
       "14295  95333_912         9   95333          912   \n",
       "14296  95333_913         9   95333          913   \n",
       "14297  95333_914         9   95333          914   \n",
       "14298  95333_915         9   95333          915   \n",
       "14299  95333_916         9   95333          916   \n",
       "\n",
       "                                   annotation          location  \\\n",
       "0              [dad with recent heart attcak]         [696 724]   \n",
       "1                 [mom with \"thyroid disease]         [668 693]   \n",
       "2                            [chest pressure]         [203 217]   \n",
       "3            [intermittent episodes, episode]  [70 91, 176 183]   \n",
       "4      [felt as if he were going to pass out]         [222 258]   \n",
       "...                                       ...               ...   \n",
       "14295                                      []                []   \n",
       "14296                                      []                []   \n",
       "14297                              [photobia]         [274 282]   \n",
       "14298                      [no sick contacts]         [421 437]   \n",
       "14299                      [Subjective fever]         [314 330]   \n",
       "\n",
       "                                            feature_text  \\\n",
       "0      Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                     Family-history-of-thyroid-disorder   \n",
       "2                                         Chest-pressure   \n",
       "3                                  Intermittent-symptoms   \n",
       "4                                            Lightheaded   \n",
       "...                                                  ...   \n",
       "14295                        Family-history-of-migraines   \n",
       "14296                                             Female   \n",
       "14297                                        Photophobia   \n",
       "14298                          No-known-illness-contacts   \n",
       "14299                                   Subjective-fever   \n",
       "\n",
       "                                              pn_history  annotation_length  \n",
       "0      HPI: 17yo M presents with palpitations. Patien...                  1  \n",
       "1      HPI: 17yo M presents with palpitations. Patien...                  1  \n",
       "2      HPI: 17yo M presents with palpitations. Patien...                  1  \n",
       "3      HPI: 17yo M presents with palpitations. Patien...                  2  \n",
       "4      HPI: 17yo M presents with palpitations. Patien...                  1  \n",
       "...                                                  ...                ...  \n",
       "14295  Stephanie madden is a 20 year old woman compla...                  0  \n",
       "14296  Stephanie madden is a 20 year old woman compla...                  0  \n",
       "14297  Stephanie madden is a 20 year old woman compla...                  1  \n",
       "14298  Stephanie madden is a 20 year old woman compla...                  1  \n",
       "14299  Stephanie madden is a 20 year old woman compla...                  1  \n",
       "\n",
       "[14300 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader()\n",
    "dl.load()\n",
    "dl.merge()\n",
    "\n",
    "dl.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14300/14300 [07:19<00:00, 32.57it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_label(df_annotation, df_history, df_annotation_length,\n",
    "                 tfhub_handle_preprocess, seq_length=500):\n",
    "    \"\"\"Densify location using tokenization.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_annotation : ndarray\n",
    "        Target of the task. Can be none, one or more.\n",
    "\n",
    "    df_history : ndarray\n",
    "        Text from which to extract annotation(s).\n",
    "\n",
    "    df_annotation_length : ndarray\n",
    "        Number of annotations per history.\n",
    "\n",
    "    seq_length : int\n",
    "        Maximum number of words in an tokenized history.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label : Tensor\n",
    "        Contains 0 if word is not part of the annotation and 1 otherwise.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    About ~7mn of elapsed time. Can increase the third for loop from ~100mn to\n",
    "    ~10ms using tf.math functions. WIP.\n",
    "    ```python\n",
    "    out_2_sum = tf.math.reduce_sum(tf.cast(tf.concat([\n",
    "        out_2['input_word_ids'] == tf.slice(out_1_extracted, [0, idx], [1, 1])\n",
    "        for idx in range(out_1_lenght-2)\n",
    "    ], axis=0), tf.int8), axis=0)\n",
    "    [...]\n",
    "    ```\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    The `seq_length` variable is by default set to 500 according to `this\n",
    "    notebook <https://www.kaggle.com/yasufuminakama/\n",
    "    nbme-deberta-base-baseline-train?scriptVersionId=87264998&cellId=25>` where\n",
    "    the max lenght was found to be 466.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load processing function\n",
    "    preprocessor = hub.load(tfhub_handle_preprocess)\n",
    "\n",
    "    # Step 1: tokenize batches of text inputs.\n",
    "    text_inputs = [tf.keras.layers.Input(shape=(), dtype=tf.string)]\n",
    "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
    "\n",
    "    # Step 3: pack input sequences for the Transformer encoder.\n",
    "    seq_length = 456  # Your choice here.\n",
    "    bert_pack_inputs = hub.KerasLayer(\n",
    "        preprocessor.bert_pack_inputs,\n",
    "        arguments=dict(seq_length=seq_length)  # Optional argument.\n",
    "    )\n",
    "\n",
    "    # Fill label with 0\n",
    "    label = np.zeros(shape=(len(df_annotation), max_lenght))\n",
    "\n",
    "    # Loop over row in locations vector\n",
    "    for row_idx in tqdm(range(len(df_annotation))):\n",
    "\n",
    "        # Stop if there is no annotoration\n",
    "        if df_annotation_length[row_idx] == 0:\n",
    "            continue\n",
    "\n",
    "        # Loop over location in the current row\n",
    "        history = df_history[row_idx]\n",
    "        for annotation in df_annotation[row_idx]:\n",
    "            out_1 = bert_pack_inputs([\n",
    "                tokenize(segment) for segment in [tf.constant([annotation])]\n",
    "            ])\n",
    "            out_1_lenght = tf.math.reduce_sum(out_1['input_mask'])\n",
    "            out_1_extracted = tf.slice(\n",
    "                out_1['input_word_ids'], [0, 1], [1, out_1_lenght-2]\n",
    "            )\n",
    "\n",
    "            out_2 = bert_pack_inputs([\n",
    "                tokenize(segment) for segment in [tf.constant([history])]\n",
    "            ])\n",
    "            out_2_lenght = tf.math.reduce_sum(out_2['input_mask'])\n",
    "\n",
    "            # This can be improved\n",
    "            start_idx, idx_annotation = 0, 0\n",
    "            for idx_history in range(out_2_lenght):\n",
    "                word = tf.slice(\n",
    "                    out_2['input_word_ids'], [0, idx_history], [1, 1]\n",
    "                )\n",
    "                if word == tf.slice(out_1_extracted, [0, idx_annotation], [1, 1]):\n",
    "                    if idx_annotation == 0:\n",
    "                        start_idx = idx_history\n",
    "                    idx_annotation += 1\n",
    "                    if idx_annotation == out_1_lenght.numpy()-2:\n",
    "                        break\n",
    "                else:\n",
    "                    idx_annotation = 0\n",
    "            label[row_idx][start_idx:start_idx+idx_annotation] = 1\n",
    "\n",
    "    return tf.constant(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.constant(dl.train['pn_history']),\n",
    "    create_label(\n",
    "        dl.train['annotation'], dl.train['pn_history'],\n",
    "        dl.train['annotation_length']\n",
    "    )\n",
    "))\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history : b'HPI: 17yo M presents with palpitations. Patient reports 3-4 months of intermittent episodes of \"heart beating/pounding out of my chest.\" 2 days ago during a soccer game had an episode, but this time had chest pressure and felt as if he were going to pass out (did not lose conciousness). Of note patient endorses abusing adderall, primarily to study (1-3 times per week). Before recent soccer game, took adderrall night before and morning of game. Denies shortness of breath, diaphoresis, fevers, chills, headache, fatigue, changes in sleep, changes in vision/hearing, abdominal paun, changes in bowel or urinary habits. \\r\\nPMHx: none\\r\\nRx: uses friends adderrall\\r\\nFHx: mom with \"thyroid disease,\" dad with recent heart attcak\\r\\nAll: none\\r\\nImmunizations: up to date\\r\\nSHx: Freshmen in college. Endorses 3-4 drinks 3 nights / week (on weekends), denies tabacco, endorses trying marijuana. Sexually active with girlfriend x 1 year, uses condoms'\n",
      "{'input_word_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[  101,  6522,  2072, ..., 10720,  2015,   102],\n",
      "       [  101,  6522,  2072, ..., 10720,  2015,   102],\n",
      "       [  101,  6522,  2072, ..., 10720,  2015,   102],\n",
      "       ...,\n",
      "       [  101,  2720,  1012, ...,  2038,  2025,   102],\n",
      "       [  101,  2720,  1012, ...,  2038,  2025,   102],\n",
      "       [  101,  2720,  1012, ...,  2038,  2025,   102]])>, 'input_mask': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1]])>, 'input_type_ids': <tf.Tensor: shape=(32, 128), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>}\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"keras_layer_6\" (type KerasLayer).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * Tensor(\"inputs:0\", shape=(32,), dtype=string)\n    * 128\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(32,), dtype=string)\n  â€¢ training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12404/3065874074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'history : {text_batch.numpy()[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_preprocess_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbert_pack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'location: {label_batch.numpy()[0]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML2\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_6\" (type KerasLayer).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * Tensor(\"inputs:0\", shape=(32,), dtype=string)\n    * 128\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64), RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64), RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (2 total):\n    * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n    * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n  Keyword arguments: {}\n\nCall arguments received:\n  â€¢ inputs=tf.Tensor(shape=(32,), dtype=string)\n  â€¢ training=None"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_data.take(1):\n",
    "    print(f'history : {text_batch.numpy()[0]}')\n",
    "    print(bert_preprocess_model(text_batch), end='\\n\\n')\n",
    "    print(bert_pack_inputs(text_batch), end='\\n\\n')\n",
    "    print(f'location: {label_batch.numpy()[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.7626287   0.99280983 -0.18611823  0.3667384   0.15233725  0.6550442\n",
      "  0.9681154  -0.948627    0.0021617  -0.9877732   0.0684269  -0.97630596]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.28946355  0.34321266  0.33231547 ...  0.2130081   0.71020746\n",
      "  -0.05771154]\n",
      " [-0.28742057  0.31980976 -0.23018584 ...  0.5845509  -0.21329743\n",
      "   0.7269206 ]\n",
      " [-0.6615704   0.68876845 -0.87433034 ...  0.10877228 -0.2617323\n",
      "   0.47855324]\n",
      " ...\n",
      " [-0.22561148 -0.28925583 -0.07064399 ...  0.47566003  0.83277017\n",
      "   0.4002542 ]\n",
      " [-0.2982427  -0.2747311  -0.05450499 ...  0.48849723  1.0955354\n",
      "   0.18163374]\n",
      " [-0.44378164  0.0093075   0.07223718 ...  0.17290066  1.1833248\n",
      "   0.07898001]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.8607125]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'sequence_output':  28763649    ['preprocessing[0][0]',          \n",
      "                                 (None, 128, 512),                'preprocessing[0][1]',          \n",
      "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                512)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18520/3201600278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnum_train_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_data).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=init_lr,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type='adamw'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18520/1782196176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m classifier_model.compile(optimizer=optimizer,\n\u001b[0m\u001b[0;32m      2\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                          metrics=metrics)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc48689332ded950941329c3789384d1fff51fedc3e02cba456c8c9d1955af91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
