import tensorflow as tf


def train_step(img_tensor, target):
    loss = 0
  
    with tf.GradientTape() as tape:
        features = encoder(img_tensor, training=True)
        
        # initializing the hidden state for each batch
        # because the captions are not related from image to image
        hidden, context = decoder.init_hidden_state(features, training=True)
    
        dec_input = tf.expand_dims([tokenizer.word_index['<start>']] * BATCH_SIZE_BASE, 1)
        
        for i in range(1, target.shape[1]):
            # passing the features through the decoder
            predictions, hidden, context = decoder(dec_input, features, hidden, context, training=True)
            
            loss += loss_function(target[:, i], predictions)
            train_accuracy.update_state(target[:, i], predictions)
            
            # using teacher forcing
            dec_input = tf.expand_dims(target[:, i], 1)
    
    batch_loss = loss / (target.shape[1] - 1)
    
    trainable_variables = encoder.trainable_variables + decoder.trainable_variables
    gradients = tape.gradient(loss, trainable_variables)
    gradients, _ = tf.clip_by_global_norm(gradients, 5.0)
    optimizer.apply_gradients(zip(gradients, trainable_variables))
    
    return batch_loss