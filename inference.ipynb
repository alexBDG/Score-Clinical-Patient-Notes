{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports.\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# TensorFlow imports.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text # To use TensorFlow Hub this import is mandatory\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "from datasets.loading import TrainLoader, TestLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert#loading_models_from_tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "EPOCHS = 1\n",
    "SEQ_LENGTH = 512\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2\"\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running on GPU\n",
      "[INFO] REPLICAS: 1\n",
      "[INFO] Compute dtype: float32\n",
      "[INFO] Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, set appropriate distribution strategy (CPU/GPU/TPU)\n",
    "\n",
    "physical_CPU_devices = tf.config.list_physical_devices('CPU')\n",
    "physical_GPU_devices = tf.config.list_physical_devices('GPU')\n",
    "physical_TPU_devices = tf.config.list_physical_devices('TPU')\n",
    "\n",
    "try:\n",
    "    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set. On Kaggle this is always the case.\n",
    "    print('[INFO] Running on TPU ', TPU.master())\n",
    "except:\n",
    "    TPU = None\n",
    "    if len(physical_GPU_devices)>0:\n",
    "        print('[INFO] Running on GPU')\n",
    "    else:\n",
    "        print('[INFO] Running on CPU')\n",
    "\n",
    "\n",
    "if TPU:\n",
    "    tf.config.experimental_connect_to_cluster(TPU)\n",
    "    tf.tpu.experimental.initialize_tpu_system(TPU)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(TPU)\n",
    "    # enable XLA optmizations\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "else:\n",
    "    # default distribution strategy in Tensorflow.\n",
    "    # Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'[INFO] REPLICAS: {REPLICAS}')\n",
    "\n",
    "# # set half precision policy\n",
    "mixed_precision.set_policy('mixed_bfloat16' if TPU else 'float32')\n",
    "\n",
    "print('[INFO] Compute dtype: {}'.format(\n",
    "    mixed_precision.global_policy().compute_dtype\n",
    "))\n",
    "print('[INFO] Variable dtype: {}'.format(\n",
    "    mixed_precision.global_policy().variable_dtype\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading & merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num  \\\n",
       "0  00016_000         0      16            0   \n",
       "1  00016_001         0      16            1   \n",
       "2  00016_002         0      16            2   \n",
       "3  00016_003         0      16            3   \n",
       "4  00016_004         0      16            4   \n",
       "\n",
       "                                        feature_text  \\\n",
       "0  Family-history-of-MI-OR-Family-history-of-myoc...   \n",
       "1                 Family-history-of-thyroid-disorder   \n",
       "2                                     Chest-pressure   \n",
       "3                              Intermittent-symptoms   \n",
       "4                                        Lightheaded   \n",
       "\n",
       "                                          pn_history  \n",
       "0  HPI: 17yo M presents with palpitations. Patien...  \n",
       "1  HPI: 17yo M presents with palpitations. Patien...  \n",
       "2  HPI: 17yo M presents with palpitations. Patien...  \n",
       "3  HPI: 17yo M presents with palpitations. Patien...  \n",
       "4  HPI: 17yo M presents with palpitations. Patien...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = TestLoader()\n",
    "dl.load()\n",
    "dl.merge()\n",
    "\n",
    "dl.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test data...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] test data...')\n",
    "test_data = tf.data.Dataset.from_tensor_slices((\n",
    "    tf.constant(dl.data['pn_history'].to_numpy()),\n",
    "))\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "test_data = test_data.cache()\n",
    "test_data = test_data.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processing function\n",
    "preprocessor = hub.load(tfhub_handle_preprocess)\n",
    "\n",
    "# Step 1: tokenize batches of text inputs.\n",
    "text_inputs = [tf.keras.layers.Input(shape=(), dtype=tf.string)]\n",
    "tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
    "tokenized_inputs = [tokenize(segment) for segment in text_inputs]\n",
    "\n",
    "# Step 3: pack input sequences for the Transformer encoder.\n",
    "bert_pack_inputs = hub.KerasLayer(\n",
    "    preprocessor.bert_pack_inputs,\n",
    "    arguments=dict(seq_length=SEQ_LENGTH)  # Optional argument.\n",
    ")\n",
    "encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "\n",
    "bert_preprocess_model_512 = tf.keras.Model(text_inputs, encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      : (1, 512)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "# text_preprocessed = bert_preprocess_model(text_test)\n",
    "text_preprocessed = bert_preprocess_model_512(tf.constant(text_test))\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bert model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.7626282   0.9928099  -0.18611862  0.3667383   0.15233758  0.655044\n",
      "  0.9681154  -0.94862705  0.0021616  -0.9877732   0.06842764 -0.97630596]\n",
      "Sequence Outputs Shape:(1, 512, 512)\n",
      "Sequence Outputs Values:[[-0.28946292  0.34321183  0.33231512 ...  0.21300802  0.7102092\n",
      "  -0.05771042]\n",
      " [-0.28741995  0.31980985 -0.23018652 ...  0.5845511  -0.21329862\n",
      "   0.72692007]\n",
      " [-0.6615692   0.68876815 -0.8743301  ...  0.1087728  -0.26173076\n",
      "   0.47855455]\n",
      " ...\n",
      " [-0.22561137 -0.2892573  -0.07064426 ...  0.47566032  0.8327724\n",
      "   0.40025347]\n",
      " [-0.2982421  -0.27473164 -0.05450544 ...  0.4884972   1.0955367\n",
      "   0.18163365]\n",
      " [-0.4437818   0.00930662  0.07223704 ...  0.17290089  1.1833239\n",
      "   0.07897975]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    # preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    # encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder_inputs = bert_preprocess_model_512(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(SEQ_LENGTH, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2174dc01460>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "classifier_model.load_weights('output/weights/model_epoch_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " model (Functional)             {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 512),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 512),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 512)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'encoder_outputs':  28763649    ['model[1][0]',                  \n",
      "                                 [(None, 512, 512),               'model[1][1]',                  \n",
      "                                 (None, 512, 512),                'model[1][2]']                  \n",
      "                                 (None, 512, 512),                                                \n",
      "                                 (None, 512, 512)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                512),                                                             \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 512, 512),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 512)}                                                       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 512)          262656      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,026,305\n",
      "Trainable params: 29,026,304\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(predictions, threshold=THRESHOLD):\n",
    "    results = []\n",
    "    for pred in predictions:\n",
    "        result = np.where(pred >= threshold)[0] + 1\n",
    "        result = [\n",
    "            list(g) for _, g in itertools.groupby(\n",
    "                result, key=lambda n, c=itertools.count(): n - next(c)\n",
    "            )\n",
    "        ]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 108;113 114;118 120;125 127;130 130;135 135;142 142;144 145;148 148;174 174;193 193;196 196;204 204;210 210;380 380',\n",
       " '2 108;113 114;118 120;125 127;130 130;135 135;142 142;144 145;148 148;174 174;193 193;196 196;204 204;210 210;380 380',\n",
       " '2 108;113 114;118 120;125 127;130 130;135 135;142 142;144 145;148 148;174 174;193 193;196 196;204 204;210 210;380 380',\n",
       " '2 108;113 114;118 120;125 127;130 130;135 135;142 142;144 145;148 148;174 174;193 193;196 196;204 204;210 210;380 380',\n",
       " '2 108;113 114;118 120;125 127;130 130;135 135;142 142;144 145;148 148;174 174;193 193;196 196;204 204;210 210;380 380']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier_model.predict(test_data)\n",
    "pred = tf.sigmoid(pred).numpy()\n",
    "get_result(pred, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['id', 'location']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc48689332ded950941329c3789384d1fff51fedc3e02cba456c8c9d1955af91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
